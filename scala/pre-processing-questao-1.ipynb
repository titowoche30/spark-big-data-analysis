{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brave-parliament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098fd164badd4e3a9f0769a4c3378ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>5</td><td>application_1615586826116_0007</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-90-155.ec2.internal:20888/proxy/application_1615586826116_0007/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-84-97.ec2.internal:8042/node/containerlogs/container_1615586826116_0007_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res1: org.apache.spark.SparkContext = org.apache.spark.SparkContext@5d382934\n"
     ]
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dominican-ethnic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ff7bc0797341868a71488d7b7cb338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import org.apache.spark.sql.DataFrame\n",
      "import org.apache.spark.sql.functions.{col, element_at, split, monotonically_increasing_id, concat, lit}\n",
      "import org.apache.spark.sql.types._\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.functions.{col, element_at, split,monotonically_increasing_id,concat,lit}\n",
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "decimal-little",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f55a3cd49446c2800c9dcf5426fea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preProcessingDF: (df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
     ]
    }
   ],
   "source": [
    " def preProcessingDF(df: DataFrame):DataFrame = {\n",
    "     val colsToDrop: List[String] = List(\"_c0\",\"_c2\",\"_c3\",\"_c4\",\"_c5\",\"_c6\",\"_c9\",\"_c10\",\"_c11\",\"_c12\",\n",
    "                                         \"_c13\",\"_c14\",\"_c15\",\"_c16\",\"_c17\",\"_c18\",\"_c19\",\"_c20\",\"_c21\",\n",
    "                                         \"_c22\",\"_c23\",\"_c24\",\"_c25\",\"_c26\",\"_c27\",\"_c28\",\"_c29\",\"_c30\",\"_c31\")\n",
    "     \n",
    "        (df.drop(colsToDrop : _*)\n",
    "         .withColumn(\"arrayHour\", split(col(\"_c7\"),\" \"))\n",
    "         .withColumn(\"Hour\", element_at(col(\"arrayHour\"),4))\n",
    "         .drop(\"arrayHour\",\"_c7\")\n",
    "         .withColumn(\"Date\",concat(col(\"_c8\"), lit(\" \"),col(\"Hour\")))\n",
    "         .withColumnRenamed(\"_c1\",\"Tweets\")\n",
    "         .drop(\"Hour\",\"_c8\")\n",
    "         .withColumn(\"ID\", monotonically_increasing_id().cast(LongType))\n",
    "         .withColumn(\"Date\",col(\"Date\").cast(TimestampType))\n",
    "         .withColumn(\"Tweets\",col(\"Tweets\").cast(StringType))\n",
    "         )\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "separated-perspective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ce4d6cb06b441cb2e1a3e3d4cd895e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_path: String = s3://trab4-bucket/datasets/debate-tweets.csv\n",
      "df: org.apache.spark.sql.DataFrame = [_c0: bigint, _c1: string ... 30 more fields]\n"
     ]
    }
   ],
   "source": [
    "val s3_path = \"s3://trab4-bucket/datasets/debate-tweets.csv\"\n",
    "\n",
    "val df =   ( spark.read\n",
    "  .option(\"inferSchema\",\"true\")\n",
    "  .option(\"header\",\"false\")\n",
    "  .option(\"sep\",\"\\t\")\n",
    "  .csv(s3_path) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "characteristic-logistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cc1ee417f14e25b61592c7319c1536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_processed: org.apache.spark.sql.DataFrame = [Tweets: string, Date: timestamp ... 1 more field]\n"
     ]
    }
   ],
   "source": [
    "val df_processed = preProcessingDF(df)\n",
    "df_processed.write.parquet(\"s3://trab4-bucket/datasets/debate-tweets.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
